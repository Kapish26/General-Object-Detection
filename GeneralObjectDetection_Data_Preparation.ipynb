{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneralObjectDetection_Data_Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-YfLxbCoWge"
      },
      "source": [
        "# !pip install openimages"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDy4HgsulwEm"
      },
      "source": [
        "#import basic libraries\n",
        "import numpy as np\n",
        "import subprocess as sbp\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "#import cv2 for image visualization,resizing\n",
        "import cv2 \n",
        "\n",
        "#for downloading images and their annotations from openimages api\n",
        "from openimages.download import download_dataset\n",
        "#for parsing xml\n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr-OixNQh9Yh"
      },
      "source": [
        "#downloading dataset\n",
        "download_dataset(\"/dataset_open_images\", [\"Bottle\", \"Fedora\"] , annotation_format=\"pascal\" , limit = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX-LTKE8Ccgk"
      },
      "source": [
        " def create_directories(dataset = \"/dataset\") :\n",
        "  '''\n",
        "    This function creates train, test, validation directories in a given path\n",
        "\n",
        "    params :\n",
        "      dataset : path where the train, test and validation directories are to be made -> default = \"../dataset\" \n",
        "  '''\n",
        "  if not os.path.isdir(dataset):\n",
        "    print(\"Creating directory\")\n",
        "    os.makedirs(dataset)\n",
        "    os.makedirs(os.path.join(dataset, \"train\"))\n",
        "    os.makedirs(os.path.join(dataset, \"test\"))\n",
        "    os.makedirs(os.path.join(dataset, \"val\"))\n",
        "  else:\n",
        "    print(\"Directory already exists\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRn18a1iFSys"
      },
      "source": [
        "def get_xml_paths (folder) :\n",
        "  '''\n",
        "    This function takes path of folder that contains xml paths and returns list of .xml files paths \n",
        "\n",
        "  '''\n",
        "  xml_paths = []\n",
        "  for root, dirs, filenames in os.walk(folder):\n",
        "    for name in filenames:\n",
        "        if('.xml' in name ) :\n",
        "          xml_paths.append(os.path.join(root,name))\n",
        "  return xml_paths"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HazTHlcIjacz"
      },
      "source": [
        "def parse_xml (xml_path):\n",
        "  '''\n",
        "    This function takes xml path and returns beautiful soup content of xml\n",
        "  '''\n",
        "  content = [] \n",
        "  with open(xml_path , \"r\") as file :\n",
        "    content = file.readlines()\n",
        "    content = \"\".join(content)\n",
        "    bs_content = bs (content , \"lxml\")\n",
        "  return bs_content"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nGemK3iXsDe"
      },
      "source": [
        "def create_info(year , month , day) :\n",
        "  '''\n",
        "    This function creates and returns info that is required in coc0_annotations format \n",
        "  '''\n",
        "  info = {}\n",
        "  info[\"year\"] = year\n",
        "  info[\"version\"] = 1 \n",
        "  info[\"description\"] = \"\"\n",
        "  info[\"contributor\"] = \"AKI\"\n",
        "  info[\"url\"] = \"\"\n",
        "  info[\"date_created\"] = '{}-{}-{}'.format(year, month, day)\n",
        "  return info"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0dX3WMSn0Gc"
      },
      "source": [
        "def resizing_image(img_path , x_resolution = 416 , y_resolution = 416):\n",
        "  '''\n",
        "    This function takes image path and returns resized image, xscale and yscale\n",
        "\n",
        "    params :\n",
        "      img_path : path to .jpg , .jpeg, .png file\n",
        "      x_resolution : no of pixels required on x-axis , by default 416\n",
        "      y_resolution : no of pixels required on y-axis , by default 416\n",
        "\n",
        "    returns :\n",
        "     img_resized : image resized to x_resolution * y_resolution\n",
        "     x_scale, y_scale : used for calculations of bounding box\n",
        "\n",
        "  '''\n",
        "  image_to_predict = cv2.imread(img_path,3)\n",
        "\n",
        "  y_ = image_to_predict.shape[0]\n",
        "  x_ = image_to_predict.shape[1]\n",
        "\n",
        "  x_scale = x_resolution/x_\n",
        "  y_scale = y_resolution/y_\n",
        "  # print(x_scale,y_scale)\n",
        "  img_resized = cv2.resize(image_to_predict,(x_resolution,y_resolution)); \n",
        "  return img_resized,x_scale , y_scale     "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DWDRdEDinx4"
      },
      "source": [
        "def roboflow(image_root, xml_paths, dataset_location, coco_annotation_json_path=None, x_resolution = 416 , y_resolution = 416):\n",
        "  ''' \n",
        "    This function converts the annotations given in xml format to COCO annotations format\n",
        "    \n",
        "    params : \n",
        "      image_root : folder that contains images \n",
        "      xml_paths : list of xml paths \n",
        "      dataset_location : path where the images and annotation files have to be stored\n",
        "      coco_annotation_json_path : path to annotations json file\n",
        "      x_resolution : no of pixels required on x-axis , by default 416\n",
        "      y_resolution : no of pixels required on y-axis , by default 416\n",
        "\n",
        "    \n",
        "  '''\n",
        "\n",
        "  now = datetime.datetime.now()\n",
        "  year = '{:02d}'.format(now.year)\n",
        "  month = '{:02d}'.format(now.month)\n",
        "  day = '{:02d}'.format(now.day)\n",
        "\n",
        "  #initialising values\n",
        "  annotation_id = 0 \n",
        "  id=0\n",
        "  category_id = 0\n",
        "  license_id = 1\n",
        "  category_list = []\n",
        "  counter_existing = 0 \n",
        "\n",
        "\n",
        "  #checking for pre-existing JSON file\n",
        "  if coco_annotation_json_path is not None: \n",
        "    with open(coco_annotation_json_path , \"r\") as json_file :\n",
        "      coco_annotation = json.load(json_file)\n",
        "      counter = len(coco_annotation.get(\"images\")) \n",
        "      counter_ann = len(coco_annotation.get(\"annotations\"))\n",
        "\n",
        "      category_list = list(map(lambda catagory: catagory['name'], coco_annotation.get(\"categories\")))\n",
        "      category_id = len(coco_annotation.get(\"categories\")) #TODO: fix how id number is calculated, might collide with other IDs if a category is deleted\n",
        "\n",
        "      if not (category_id == len(category_list)):\n",
        "        print(\"Length mismatch while getting category names\")\n",
        "\n",
        "  else:\n",
        "    counter =0\n",
        "    counter_ann=0\n",
        "    coco_annotation = {}\n",
        "    coco_annotation[\"info\"] = create_info(year , month , day)\n",
        "    coco_annotation[\"licenses\"] =  [{\"id\": license_id,\"url\": \"\",\"name\": \"Unknown\"}]\n",
        "    coco_annotation[\"categories\"] = []\n",
        "    coco_annotation[\"images\"] = []\n",
        "    coco_annotation[\"annotations\"] = []\n",
        "    \n",
        "  for image_index, xml_path in enumerate(xml_paths) :\n",
        "    parsed_xml = parse_xml(xml_path)\n",
        "    image_path = os.path.join(dataset_location, parsed_xml.find(\"filename\").text)\n",
        "    if os.path.isfile(image_path):\n",
        "      # print(image_index,xml_path)\n",
        "      counter_existing = counter_existing+1\n",
        "      continue \n",
        "    image = {}\n",
        "    image[\"id\"] = image_index + counter - counter_existing\n",
        "    image[\"license\"] = license_id\n",
        "    image[\"file_name\"] = parsed_xml.find(\"filename\").text\n",
        "    image[\"height\"] = y_resolution\n",
        "    image[\"width\"] = x_resolution\n",
        "    image[\"date_captured\"] = '{}-{}-{}'.format(year, month, day)\n",
        "\n",
        "    # Add image to dataset folder\n",
        "    image_path = os.path.join(image_root, image[\"file_name\"])\n",
        "    img_resized , x_scale , y_scale = resizing_image(img_path=image_path , x_resolution= x_resolution , y_resolution= y_resolution)\n",
        "    cv2.imwrite(os.path.join(dataset_location,image[\"file_name\"]) , img_resized)\n",
        "  \n",
        "\n",
        "    #Adding image to JSON\n",
        "    coco_annotation[\"images\"].append(image)\n",
        "    names = parsed_xml.find_all(\"name\")\n",
        "    xmins = parsed_xml.find_all(\"xmin\")\n",
        "    xmaxs = parsed_xml.find_all(\"xmax\")\n",
        "    ymins = parsed_xml.find_all(\"ymin\")\n",
        "    ymaxs = parsed_xml.find_all(\"ymax\")\n",
        "\n",
        "    for i in range(len(names)) :\n",
        "      name = names[i].text \n",
        "\n",
        "      if name not in category_list :\n",
        "        category_list.append(name)\n",
        "        dic = {'id' : category_id , \"name\" : name , \"supercategory\" : \"none\"}\n",
        "        coco_annotation[\"categories\"].append(dic)\n",
        "        id += 1 # TODO: Redo how IDs are calculated\n",
        "\n",
        "      #Creating the annotation\n",
        "      annotation = {}\n",
        "      annotation[\"id\"] = annotation_id + counter_ann # TODO: Redo how annotation IDs are calculated \n",
        "      annotation_id += 1 \n",
        "      annotation[\"image_id\"] = image[\"id\"]\n",
        "      annotation[\"category_id\"] = category_list.index(name)\n",
        "      annotation[\"bbox\"] = [\n",
        "              x_scale*int(xmins[i].text) , \n",
        "              y_scale*int(ymins[i].text),\n",
        "              x_scale*(int(xmaxs[i].text)-int(xmins[i].text)),\n",
        "              y_scale*(int(ymaxs[i].text)-int(ymins[i].text))\n",
        "      ]\n",
        "      annotation[\"area\"] = ((x_scale*(int(xmaxs[i].text)-int(xmins[i].text))) * (y_scale*(int(ymaxs[i].text)-int(ymins[i].text))))\n",
        "      annotation[\"segmentation\"] = []\n",
        "      annotation[\"iscrowd\"] = 0\n",
        "\n",
        "      #Adding the annotation to JSON\n",
        "      coco_annotation[\"annotations\"].append(annotation)\n",
        "\n",
        "      \n",
        "  with open(os.path.join(dataset_location, \"_annotations.coco.json\"), \"w\") as json_file :\n",
        "    json.dump(coco_annotation , json_file)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSMOOiGvR_Iu"
      },
      "source": [
        "def add_to_dataset(paths, dataset = \"/dataset\", percentages = [90, 5, 5]):\n",
        "  '''\n",
        "    This function splits and adds images in train, test, validation dirctories\n",
        "\n",
        "    params : \n",
        "      paths : paths to directory where the data is stored\n",
        "      dataset : path to directory where the images and annotations file have to be stored\n",
        "      percentages : Split perecntage of total data into train, validation and test\n",
        "  '''\n",
        "  for path in paths:\n",
        "    print(\"Started: \" + path)\n",
        "    create_directories(dataset)\n",
        "    image_root = os.path.join(path, \"images\")\n",
        "    pascal = os.path.join(path, \"pascal\")\n",
        "    xml_paths = get_xml_paths(pascal)\n",
        "\n",
        "    if(sum(percentages) != 100):\n",
        "      print(\"Split sumcheck failed going with 90, 5, 5 split\")\n",
        "      percentages = [90, 5, 5]\n",
        "\n",
        "    train, val, test = np.split(xml_paths, [int(len(xml_paths)*percentages[0]/100), int(len(xml_paths)*(percentages[0] + percentages[1])/100)])\n",
        "\n",
        "    # TODO: find better conversion method\n",
        "    train = train.tolist()\n",
        "    val = val.tolist()\n",
        "    test = test.tolist()\n",
        "\n",
        "    splits = {\n",
        "        \"train\" : train,\n",
        "        \"val\" : val,\n",
        "        \"test\": test\n",
        "    }\n",
        "\n",
        "    print(len(train), len(test), len(val))\n",
        "    print(type(train), type(test), type(val))\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "      dataset_location = os.path.join(dataset, split)\n",
        "      annotation_file_path = os.path.join(dataset_location, \"_annotations.coco.json\")\n",
        "      annotation_file_path = annotation_file_path if os.path.isfile(annotation_file_path) else None\n",
        "      roboflow(image_root, splits[split], dataset_location, coco_annotation_json_path = annotation_file_path)\n",
        "\n",
        "    print(\"Completed: \" + path)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zDWgIscg19U"
      },
      "source": [
        "def generate_paths(root, names):\n",
        "  return [os.path.join(root, name) for name in names]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35QLqbpfXn41"
      },
      "source": [
        "add_to_dataset(paths = generate_paths(\"/dataset_open_images\", [\"fedora\", \"bottle\"]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q81qiOWmZpKZ"
      },
      "source": [
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    with open(\"/dataset/{}/_annotations.coco.json\".format(split) , \"r\") as json_file :\n",
        "      coco_annotation = json.load(json_file)\n",
        "      counter = len(coco_annotation.get(\"images\")) \n",
        "    print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0OHtlsYfRgs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}